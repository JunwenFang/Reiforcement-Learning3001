# Reinforcement-Learning-3001


Backgroundï¼š Texas Hold'em Poker is an imperfect-information game requiring players to make decisions under uncertainty, with hidden information about opponents' cards and strategies.
This environment is naturally aligned with reinforcement learning (RL), emphasizing sequential decision-making, reward optimization, and adaptive strategy formulation.
Project Objective
Study the impact of player numbers (1v1 vs multi-agent) on agent training dynamics and strategic behavior.
Compare the learning performance of two algorithms:
Q-Learning: Classical RL method for state-action value optimization
Counterfactual Regret Minimization (CFR): Specialized algorithm for imperfect-information games

Research Focus
How does the complexity introduced by more players affect the convergence and final strategies of different learning agents?
Does CFR or Q-Learning adapt better to increased uncertainty and opponent variability?

