# Reinforcement-Learning-3001


# ğŸ® Poker AI: Q-Learning vs CFR in Texas Hold'em

## ğŸ§  Background
**Texas Hold'em Poker** is an imperfect-information game that requires players to make decisions under uncertainty, due to hidden information about opponents' cards and strategies.

This environment naturally aligns with **reinforcement learning (RL)**, which focuses on:
- Sequential decision-making
- Reward optimization
- Adaptive strategy formulation

---

## ğŸ¯ Project Objective
- Study the **impact of player numbers** (1v1 vs multi-agent) on agent training dynamics and strategic behavior.
- Compare the learning performance of two algorithms:
  - **Q-Learning**: A classical RL method for state-action value optimization.
  - **Counterfactual Regret Minimization (CFR)**: A specialized algorithm tailored for imperfect-information games like poker.

---

## ğŸ” Research Focus
- How does the **complexity introduced by more players** affect the convergence speed and final strategies of different learning agents?
- Does **CFR or Q-Learning** adapt better to **increased uncertainty and opponent variability** in multi-agent settings?


